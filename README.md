# Threat-Mitigation-in-Machine-Learning-Systems
A hands-on research project focused on detecting and defending against data poisoning and adversarial attacks in machine learning systems. Conducted multiple experiments using the MNIST dataset, exploring both training-time and inference-time vulnerabilities, and evaluating various defensive strategies to enhance model robustness.
